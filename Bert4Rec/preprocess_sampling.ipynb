{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".venv",
   "display_name": ".venv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from abc import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ngtze\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  userId  movieId  rating  timestamp_ratings               tag  \\\n",
       "0           0       4     7569     3.5         1573943431  so bad it's good   \n",
       "1           1   18853     7569     3.0         1248068143               007   \n",
       "2           2   18853     7569     3.0         1248068143        james bond   \n",
       "3           3   21096     7569     4.0         1269243364         franchise   \n",
       "4           4   21096     7569     4.0         1269243364        James Bond   \n",
       "\n",
       "   timestamp_tags                title                          genres_x  \\\n",
       "0      1573943455  You Only Live Twice  Action|Adventure|Sci-Fi|Thriller   \n",
       "1      1248068150  You Only Live Twice  Action|Adventure|Sci-Fi|Thriller   \n",
       "2      1248068148  You Only Live Twice  Action|Adventure|Sci-Fi|Thriller   \n",
       "3      1246471298  You Only Live Twice  Action|Adventure|Sci-Fi|Thriller   \n",
       "4      1246471305  You Only Live Twice  Action|Adventure|Sci-Fi|Thriller   \n",
       "\n",
       "   MovieYear  ...        originalTitle isAdult startYear endYear  \\\n",
       "0       1977  ...  You Only Live Twice       0      1967      \\N   \n",
       "1       1977  ...  You Only Live Twice       0      1967      \\N   \n",
       "2       1977  ...  You Only Live Twice       0      1967      \\N   \n",
       "3       1977  ...  You Only Live Twice       0      1967      \\N   \n",
       "4       1977  ...  You Only Live Twice       0      1967      \\N   \n",
       "\n",
       "   runtimeMinutes                   genres_y averageRating numVotes  \\\n",
       "0             117  Action,Adventure,Thriller           6.9    99691   \n",
       "1             117  Action,Adventure,Thriller           6.9    99691   \n",
       "2             117  Action,Adventure,Thriller           6.9    99691   \n",
       "3             117  Action,Adventure,Thriller           6.9    99691   \n",
       "4             117  Action,Adventure,Thriller           6.9    99691   \n",
       "\n",
       "   directors                                  writers  \n",
       "0  nm0318150  nm0089169,nm0001094,nm0001220,nm0420845  \n",
       "1  nm0318150  nm0089169,nm0001094,nm0001220,nm0420845  \n",
       "2  nm0318150  nm0089169,nm0001094,nm0001220,nm0420845  \n",
       "3  nm0318150  nm0089169,nm0001094,nm0001220,nm0420845  \n",
       "4  nm0318150  nm0089169,nm0001094,nm0001220,nm0420845  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp_ratings</th>\n      <th>tag</th>\n      <th>timestamp_tags</th>\n      <th>title</th>\n      <th>genres_x</th>\n      <th>MovieYear</th>\n      <th>...</th>\n      <th>originalTitle</th>\n      <th>isAdult</th>\n      <th>startYear</th>\n      <th>endYear</th>\n      <th>runtimeMinutes</th>\n      <th>genres_y</th>\n      <th>averageRating</th>\n      <th>numVotes</th>\n      <th>directors</th>\n      <th>writers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4</td>\n      <td>7569</td>\n      <td>3.5</td>\n      <td>1573943431</td>\n      <td>so bad it's good</td>\n      <td>1573943455</td>\n      <td>You Only Live Twice</td>\n      <td>Action|Adventure|Sci-Fi|Thriller</td>\n      <td>1977</td>\n      <td>...</td>\n      <td>You Only Live Twice</td>\n      <td>0</td>\n      <td>1967</td>\n      <td>\\N</td>\n      <td>117</td>\n      <td>Action,Adventure,Thriller</td>\n      <td>6.9</td>\n      <td>99691</td>\n      <td>nm0318150</td>\n      <td>nm0089169,nm0001094,nm0001220,nm0420845</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>18853</td>\n      <td>7569</td>\n      <td>3.0</td>\n      <td>1248068143</td>\n      <td>007</td>\n      <td>1248068150</td>\n      <td>You Only Live Twice</td>\n      <td>Action|Adventure|Sci-Fi|Thriller</td>\n      <td>1977</td>\n      <td>...</td>\n      <td>You Only Live Twice</td>\n      <td>0</td>\n      <td>1967</td>\n      <td>\\N</td>\n      <td>117</td>\n      <td>Action,Adventure,Thriller</td>\n      <td>6.9</td>\n      <td>99691</td>\n      <td>nm0318150</td>\n      <td>nm0089169,nm0001094,nm0001220,nm0420845</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>18853</td>\n      <td>7569</td>\n      <td>3.0</td>\n      <td>1248068143</td>\n      <td>james bond</td>\n      <td>1248068148</td>\n      <td>You Only Live Twice</td>\n      <td>Action|Adventure|Sci-Fi|Thriller</td>\n      <td>1977</td>\n      <td>...</td>\n      <td>You Only Live Twice</td>\n      <td>0</td>\n      <td>1967</td>\n      <td>\\N</td>\n      <td>117</td>\n      <td>Action,Adventure,Thriller</td>\n      <td>6.9</td>\n      <td>99691</td>\n      <td>nm0318150</td>\n      <td>nm0089169,nm0001094,nm0001220,nm0420845</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>21096</td>\n      <td>7569</td>\n      <td>4.0</td>\n      <td>1269243364</td>\n      <td>franchise</td>\n      <td>1246471298</td>\n      <td>You Only Live Twice</td>\n      <td>Action|Adventure|Sci-Fi|Thriller</td>\n      <td>1977</td>\n      <td>...</td>\n      <td>You Only Live Twice</td>\n      <td>0</td>\n      <td>1967</td>\n      <td>\\N</td>\n      <td>117</td>\n      <td>Action,Adventure,Thriller</td>\n      <td>6.9</td>\n      <td>99691</td>\n      <td>nm0318150</td>\n      <td>nm0089169,nm0001094,nm0001220,nm0420845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>21096</td>\n      <td>7569</td>\n      <td>4.0</td>\n      <td>1269243364</td>\n      <td>James Bond</td>\n      <td>1246471305</td>\n      <td>You Only Live Twice</td>\n      <td>Action|Adventure|Sci-Fi|Thriller</td>\n      <td>1977</td>\n      <td>...</td>\n      <td>You Only Live Twice</td>\n      <td>0</td>\n      <td>1967</td>\n      <td>\\N</td>\n      <td>117</td>\n      <td>Action,Adventure,Thriller</td>\n      <td>6.9</td>\n      <td>99691</td>\n      <td>nm0318150</td>\n      <td>nm0089169,nm0001094,nm0001220,nm0420845</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data = pd.read_excel('../data/processed_data/full_data.xlsx')\n",
    "data.drop(co)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For this model we only need the history of ratings\n",
    "def getRatings()\n",
    "\n",
    "\n",
    "## Get Size of the Data\n",
    "def get_count(tp, id):\n",
    "    groups = tp[[id]].groupby(id, as_index=False)\n",
    "    count = groups.size()\n",
    "    return count\n",
    "\n",
    "#Get movies and users which share at least 3 intersection\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users.\n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "\n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "\n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId')\n",
    "    return tp, usercount, itemcount\n",
    "\n",
    "#Possible use to reduce size of data (we are only interested in the movies that were rated 4-5 )\n",
    "def make_implicit(df, min_rating):\n",
    "    print('Turning into implicit ratings')\n",
    "    df = df[df['rating'] >= min_rating]\n",
    "    # return df[['uid', 'sid', 'timestamp']]\n",
    "    return df\n",
    "\n",
    "\n",
    "#Probability Mass Distibution of user and movie\n",
    "def densify_index(df):\n",
    "    print('Densifying index')\n",
    "    umap = {u: i for i, u in enumerate(set(df['uid']))}\n",
    "    smap = {s: i for i, s in enumerate(set(df['sid']))}\n",
    "    df['uid'] = df['uid'].map(umap)\n",
    "    df['sid'] = df['sid'].map(smap)\n",
    "    return df, umap, smap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "#Create a Dataset Class that cr\n",
    "class ML20MDataset(metaclass=ABCMeta):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.min_rating = args.min_rating\n",
    "        self.min_uc = args.min_uc\n",
    "        self.min_sc = args.min_sc\n",
    "        self.split = args.split\n",
    "\n",
    "        assert self.min_uc >= 2, 'Need at least 2 ratings per user for validation and test'\n",
    "    \n",
    "    def make_implicit(self, df):\n",
    "        print('Turning into implicit ratings')\n",
    "        df = df[df['rating'] >= self.min_rating]\n",
    "        # return df[['uid', 'sid', 'timestamp']]\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    def densify_index(self, df):\n",
    "        print('Densifying index')\n",
    "        umap = {u: i for i, u in enumerate(set(df['uid']))}\n",
    "        smap = {s: i for i, s in enumerate(set(df['sid']))}\n",
    "        df['uid'] = df['uid'].map(umap)\n",
    "        df['sid'] = df['sid'].map(smap)\n",
    "        return df, umap, smap\n",
    "\n",
    "    def split_df(self, df, user_count):\n",
    "        if self.args.split == 'leave_one_out':\n",
    "            print('Splitting')\n",
    "            user_group = df.groupby('uid')\n",
    "            user2items = user_group.progress_apply(lambda d: list(d.sort_values(by='timestamp')['sid']))\n",
    "            train, val, test = {}, {}, {}\n",
    "            for user in range(user_count):\n",
    "                items = user2items[user]\n",
    "                train[user], val[user], test[user] = items[:-2], items[-2:-1], items[-1:]\n",
    "            return train, val, test\n",
    "        elif self.args.split == 'holdout':\n",
    "            print('Splitting')\n",
    "            np.random.seed(self.args.dataset_split_seed)\n",
    "            eval_set_size = self.args.eval_set_size\n",
    "\n",
    "            # Generate user indices\n",
    "            permuted_index = np.random.permutation(user_count)\n",
    "            train_user_index = permuted_index[                :-2*eval_set_size]\n",
    "            val_user_index   = permuted_index[-2*eval_set_size:  -eval_set_size]\n",
    "            test_user_index  = permuted_index[  -eval_set_size:                ]\n",
    "\n",
    "            # Split DataFrames\n",
    "            train_df = df.loc[df['uid'].isin(train_user_index)]\n",
    "            val_df   = df.loc[df['uid'].isin(val_user_index)]\n",
    "            test_df  = df.loc[df['uid'].isin(test_user_index)]\n",
    "\n",
    "            # DataFrame to dict => {uid : list of sid's}\n",
    "            train = dict(train_df.groupby('uid').progress_apply(lambda d: list(d['sid'])))\n",
    "            val   = dict(val_df.groupby('uid').progress_apply(lambda d: list(d['sid'])))\n",
    "            test  = dict(test_df.groupby('uid').progress_apply(lambda d: list(d['sid'])))\n",
    "            return train, val, test\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def all_raw_file_names(cls):\n",
    "        return ['genome-scores.csv',\n",
    "                'genome-tags.csv',\n",
    "                'links.csv',\n",
    "                'movies.csv',\n",
    "                'ratings.csv',\n",
    "                'README.txt',\n",
    "                'tags.csv']\n",
    "\n",
    "    \n",
    "    def load_ratings_df(self):\n",
    "        folder_path = self._get_rawdata_folder_path()\n",
    "        file_path = folder_path.joinpath('ratings.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns = ['uid', 'sid', 'rating', 'timestamp']\n",
    "        return df\n",
    "\n",
    "       def load_dataset(self):\n",
    "        self.preprocess()\n",
    "        dataset_path = self._get_preprocessed_dataset_path()\n",
    "        dataset = pickle.load(dataset_path.open('rb'))\n",
    "        return dataset\n",
    "\n",
    "    def preprocess(self):\n",
    "        dataset_path = self._get_preprocessed_dataset_path()\n",
    "        if dataset_path.is_file():\n",
    "            print('Already preprocessed. Skip preprocessing')\n",
    "            return\n",
    "        if not dataset_path.parent.is_dir():\n",
    "            dataset_path.parent.mkdir(parents=True)\n",
    "        self.maybe_download_raw_dataset()\n",
    "        df = self.load_ratings_df()\n",
    "        df = self.make_implicit(df)\n",
    "        df = self.filter_triplets(df)\n",
    "        df, umap, smap = self.densify_index(df)\n",
    "        train, val, test = self.split_df(df, len(umap))\n",
    "        dataset = {'train': train,\n",
    "                   'val': val,\n",
    "                   'test': test,\n",
    "                   'umap': umap,\n",
    "                   'smap': smap}\n",
    "        with dataset_path.open('wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "\n",
    "\n",
    "    def _get_rawdata_root_path(self):\n",
    "        return Path(RAW_DATASET_ROOT_FOLDER)\n",
    "\n",
    "    def _get_rawdata_folder_path(self):\n",
    "        root = self._get_rawdata_root_path()\n",
    "        return root.joinpath(self.raw_code())\n",
    "\n",
    "    def _get_preprocessed_root_path(self):\n",
    "        root = self._get_rawdata_root_path()\n",
    "        return root.joinpath('preprocessed')\n",
    "\n",
    "    def _get_preprocessed_folder_path(self):\n",
    "        preprocessed_root = self._get_preprocessed_root_path()\n",
    "        folder_name = '{}_min_rating{}-min_uc{}-min_sc{}-split{}' \\\n",
    "            .format(self.code(), self.min_rating, self.min_uc, self.min_sc, self.split)\n",
    "        return preprocessed_root.joinpath(folder_name)\n",
    "\n",
    "    def _get_preprocessed_dataset_path(self):\n",
    "        folder = self._get_preprocessed_folder_path()\n",
    "        return folder.joinpath('dataset.pkl')"
   ]
  }
 ]
}