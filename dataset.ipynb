{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".venv",
   "display_name": ".venv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_movie_overlap = 1500\n",
    "min_user_overlap = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating Dataset\n"
     ]
    }
   ],
   "source": [
    "# Creating the Dataset takes incredibly long to run so we created intermediate checkpoints (saving the semi-processed data) to avoid the long process of creating the dataset again\n",
    "\n",
    "try:\n",
    "    data  = pd.read_csv('./data/processed_data/movie_lens_data.csv')\n",
    "    data = data.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "except:\n",
    "    ### Datasets as described @ https://files.grouplens.org/datasets/movielens/ml-25m-README.html\n",
    "    print(\"Creating Dataset\")\n",
    "    \"\"\"\n",
    "    All ratings are contained in the file ratings.csv.\n",
    "    Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
    "    \n",
    "    userId,movieId,rating,timestamp\n",
    "\n",
    "    The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "\n",
    "    Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "\n",
    "    Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "    \"\"\"\n",
    "    # ratings = pd.read_csv('./data/raw_data/ratings.csv')\n",
    "    data = pd.read_csv('./data/raw_data/ratings.csv')\n",
    "    ## Adding Tag Data\n",
    "    \"\"\"\n",
    "    Tags Data File Structure (tags.csv)\n",
    "    All tags are contained in the file tags.csv. \n",
    "    Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\n",
    "    \n",
    "    userId,movieId,tag,timestamp\n",
    "    \n",
    "    The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "\n",
    "    Tags are user-generated metadata about movies. \n",
    "    Each tag is typically a single word or short phrase.\n",
    "    The meaning, value, and purpose of a particular tag is determined by each user.\n",
    "\n",
    "    Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970\n",
    "    \"\"\"\n",
    "    # tag = pd.read_csv('./data/raw_data/tags.csv')\n",
    "\n",
    "    #join tag and ratings\n",
    "    # data = pd.merge(ratings, tag, on = [\"userId\", \"movieId\"], suffixes = [\"_ratings\",\"_tags\"])\n",
    "\n",
    "    ## Adding Movie Data\n",
    "\n",
    "    \"\"\"\n",
    "    Movie information is contained in the file movies.csv.\n",
    "    Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "    movieId,title,genres\n",
    "\n",
    "    Movie titles are entered manually or imported from https://www.themoviedb.org/, and include the year of release in parentheses.\n",
    "    Errors and inconsistencies may exist in these titles.\n",
    "\n",
    "    Genres are a pipe-separated list, and are selected from the following:\n",
    "\n",
    "    Action\n",
    "    Adventure\n",
    "    Animation\n",
    "    Children's\n",
    "    Comedy\n",
    "    Crime\n",
    "    Documentary\n",
    "    Drama\n",
    "    Fantasy\n",
    "    Film-Noir\n",
    "    Horror\n",
    "    Musical\n",
    "    Mystery\n",
    "    Romance\n",
    "    Sci-Fi\n",
    "    Thriller\n",
    "    War\n",
    "    Western\n",
    "    (no genres listed)\n",
    "    \"\"\"\n",
    "    movies = pd.read_csv('./data/raw_data/movies.csv')\n",
    "\n",
    "    data = data.merge(movies, on='movieId')\n",
    "\n",
    "    # data = data[data[\"rating\"] >= 3.5]\n",
    "    \n",
    "    #Clean the movie title\n",
    "    data[\"title\"] = data[\"title\"].apply(lambda x: x[:-7])\n",
    "\n",
    "    # Filter only user and movies with significant overlaps\n",
    "    item_sizes = data.groupby('movieId').size()\n",
    "    good_items = item_sizes.index[item_sizes >= min_movie_overlap]\n",
    "    data = data[data['movieId'].isin(good_items)]\n",
    "\n",
    "    user_sizes = data.groupby('userId').size()\n",
    "    good_users = user_sizes.index[user_sizes >= min_user_overlap]\n",
    "    data = data[data['userId'].isin(good_users)]\n",
    "\n",
    "    #Saving dataset into excel (Intermediate checkpoint)\n",
    "    data.to_csv(\"./data/processed_data/movie_lens_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      userId  movieId  rating   timestamp         title  \\\n",
       "860     1748      296     3.0  1025293612  Pulp Fiction   \n",
       "943     1920      296     5.0  1425578962  Pulp Fiction   \n",
       "1070    2177      296     4.0   882349917  Pulp Fiction   \n",
       "1447    2982      296     5.0  1105584969  Pulp Fiction   \n",
       "1525    3150      296     3.5  1216177794  Pulp Fiction   \n",
       "\n",
       "                           genres  \n",
       "860   Comedy|Crime|Drama|Thriller  \n",
       "943   Comedy|Crime|Drama|Thriller  \n",
       "1070  Comedy|Crime|Drama|Thriller  \n",
       "1447  Comedy|Crime|Drama|Thriller  \n",
       "1525  Comedy|Crime|Drama|Thriller  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>860</th>\n      <td>1748</td>\n      <td>296</td>\n      <td>3.0</td>\n      <td>1025293612</td>\n      <td>Pulp Fiction</td>\n      <td>Comedy|Crime|Drama|Thriller</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>1920</td>\n      <td>296</td>\n      <td>5.0</td>\n      <td>1425578962</td>\n      <td>Pulp Fiction</td>\n      <td>Comedy|Crime|Drama|Thriller</td>\n    </tr>\n    <tr>\n      <th>1070</th>\n      <td>2177</td>\n      <td>296</td>\n      <td>4.0</td>\n      <td>882349917</td>\n      <td>Pulp Fiction</td>\n      <td>Comedy|Crime|Drama|Thriller</td>\n    </tr>\n    <tr>\n      <th>1447</th>\n      <td>2982</td>\n      <td>296</td>\n      <td>5.0</td>\n      <td>1105584969</td>\n      <td>Pulp Fiction</td>\n      <td>Comedy|Crime|Drama|Thriller</td>\n    </tr>\n    <tr>\n      <th>1525</th>\n      <td>3150</td>\n      <td>296</td>\n      <td>3.5</td>\n      <td>1216177794</td>\n      <td>Pulp Fiction</td>\n      <td>Comedy|Crime|Drama|Thriller</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "329827"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    movie_features = pd.read_csv('data/processed_data/imdb_data.csv')\n",
    "    movie_features = movie_features.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "except:\n",
    "    \"\"\" \n",
    "    name.basics – Contains the following information for names:\n",
    "        nconst (string) - alphanumeric unique identifier of the name/person\n",
    "        primaryName (string)– name by which the person is most often credited\n",
    "        birthYear – in YYYY format\n",
    "        deathYear – in YYYY format if applicable\n",
    "        primaryProfession (array of strings)– the top-3 professions of the person\n",
    "        knownForTitles (array of tconsts) – titles the person is known for\n",
    "    \"\"\"\n",
    "    name_basics = pd.read_csv('./data/raw_data/names.tsv', sep='\\t')\n",
    "    \"\"\"\n",
    "    title.basics.tsv.gz - Contains the following information for titles:\n",
    "        tconst (string) - alphanumeric unique identifier of the title\n",
    "        titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "        primaryTitle (string) – the title used by the filmmakers on promotional materials at the point of release\n",
    "        originalTitle (string) - original title, in the original language\n",
    "        isAdult (boolean) - 0: non-adult title; 1: adult title\n",
    "        startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "        endYear (YYYY) – TV Series end year. \n",
    "        runtimeMinutes – primary runtime of the title, in minutes\n",
    "        genres (string array) – includes up to three genres associated with the title\n",
    "    \"\"\"\n",
    "    title_basic = pd.read_csv('./data/raw_data/title_basic.tsv', sep=\"\\t\")\n",
    "\n",
    "    \"\"\"\n",
    "    title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
    "        tconst (string) - alphanumeric unique identifier of the title\n",
    "        averageRating – weighted average of all the individual user ratings\n",
    "        numVotes - number of votes the title has received\n",
    "    \"\"\"\n",
    "    title_ratings = pd.read_csv('./data/raw_data/title_ratings.tsv', sep=\"\\t\")\n",
    "\n",
    "    \"\"\"\n",
    "    title.crew.tsv.gz – Contains the director and writer information for all the titles in IMDb. Fields include:\n",
    "        tconst (string) - alphanumeric unique identifier of the title\n",
    "        directors (array of nconsts) - director(s) of the given title\n",
    "        writers (array of nconsts) – writer(s) of the given title\n",
    "    \"\"\"\n",
    "    title_crew = pd.read_csv('./data/raw_data/directors_writers.tsv', sep=\"\\t\")\n",
    "\n",
    "\n",
    "    ## Data Processing\n",
    "    #Join Ratings to movie\n",
    "    movie_features = pd.merge(title_basic, title_ratings,on=\"tconst\" )\n",
    "\n",
    "    #Join Crew to movie\n",
    "    movie_features = movie_features.merge(title_crew, on=\"tconst\")\n",
    "\n",
    "    #Filter out movies\n",
    "    movie_features = movie_features[movie_features['titleType'] == \"movie\"]\n",
    "\n",
    "    ##Saving IMDB dataset\n",
    "    movie_features.to_csv(\"./data/processed_data/imdb_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "261414"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(movie_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine both datasets and split to train and test\n",
    "\n",
    "try:\n",
    "    train = pd.read_csv('./data/processed_data/train_data.csv')\n",
    "    test = pd.read_csv('./data/processed_data/test_data.csv')\n",
    "    final_data = pd.read_csv('./data/processed_data/full_data.csv')\n",
    "\n",
    "    train = train.drop(columns = ['Unnamed: 0'])\n",
    "    test = test.drop(columns = ['Unnamed: 0'])\n",
    "    final_data = final_data.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "except:\n",
    "    final_data = pd.merge(data, movie_features, left_on=[\"title\"], right_on=[\"originalTitle\"])\n",
    "    train, test = train_test_split(final_data, test_size = 0.2, random_state = 10, shuffle= True)\n",
    "\n",
    "    ##Saving Dataset\n",
    "    train.to_csv('./data/processed_data/train_data.csv')\n",
    "    test.to_csv('./data/processed_data/test_data.csv')\n",
    "    final_data.to_csv('./data/processed_data/full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "357955"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(final_data[\"userId\"].unique())"
   ]
  }
 ]
}